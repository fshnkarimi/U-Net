{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA5l4mnZn03B"
      },
      "source": [
        "## DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi3BYfPQvnvd"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%load_ext autoreload\n",
        "\n",
        "%autoreload 2\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "\n",
        "\n",
        "from torch.nn import Conv2d as Conv2D\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Upsample\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1EtK9dZH4pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918e5e93-d6b3-482d-b558-a30866cc2a33"
      },
      "source": [
        "!gdown --id 1opMhHAiMJVdD0eYAJEcuHZgTscgFBCpj\n",
        "!gdown --id 1uVs0yvi-HRj0yyez9MbnGwk_EsCHDLzl"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1opMhHAiMJVdD0eYAJEcuHZgTscgFBCpj\n",
            "To: /content/2d_images.zip.zip\n",
            "102MB [00:01, 91.2MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uVs0yvi-HRj0yyez9MbnGwk_EsCHDLzl\n",
            "To: /content/2d_masks.zip.zip\n",
            "100% 585k/585k [00:00<00:00, 75.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQwEuQi9U92t"
      },
      "source": [
        "%mkdir Dataset\n",
        "%mkdir Dataset/2d_images\n",
        "%mkdir Dataset/2d_masks"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhf6fHWlURN6"
      },
      "source": [
        "\n",
        "!unzip -q 2d_images.zip.zip \n",
        "!unzip -q 2d_images.zip -d Dataset/2d_images\n",
        "\n",
        "!unzip -q 2d_masks.zip.zip \n",
        "!unzip -q 2d_masks.zip -d Dataset/2d_masks"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDjVbTzKV9JI"
      },
      "source": [
        "!rm -rf 2d_images.zip.zip\n",
        "!rm -rf 2d_images.zip\n",
        "\n",
        "!rm -rf 2d_masks.zip.zip\n",
        "!rm -rf 2d_masks.zip"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr7lj5Hcyabk"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ukp9r5W9eZC"
      },
      "source": [
        "class CT_Data(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, root_dir):\n",
        "\n",
        "        self.image_frame = pd.read_csv(csv_file, skiprows=1)\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.image_frame.iloc[idx, 0])\n",
        "        mask_name = os.path.join(self.root_dir, self.image_frame.iloc[idx, 1])\n",
        "        image = cv2.imread(img_name, 0)\n",
        "        image = cv2.resize(image,(32, 32))\n",
        "        image = image.reshape((1, 32, 32))\n",
        "        mask = cv2.imread(mask_name, 0)\n",
        "        mask = cv2.resize(mask, (32, 32))\n",
        "        mask = mask.reshape((1, 32, 32))\n",
        "        sample = {'image': image, 'mask': mask}\n",
        "        return sample"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4akgB1MbygYG"
      },
      "source": [
        "img_dir = \"Dataset/2d_images/\"\n",
        "msk_dir = \"Dataset/2d_masks/\"\n",
        "with open('Dataset/Dataset.csv', 'w') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow([\"filename\", \"mask\"])\n",
        "    for p in os.listdir(img_dir):\n",
        "        image_path = os.path.join(img_dir, p)\n",
        "        mask_path = os.path.join(msk_dir, p)\n",
        "        writer.writerow([image_path, mask_path])\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
        "data = data.iloc[np.random.permutation(len(data))]\n",
        "partition = int(len(data)*0.7)\n",
        "train, validation = data[:partition], data[partition:]\n",
        "train.to_csv(\"Dataset/Train.csv\", index=False)\n",
        "validation.to_csv(\"Dataset/Validation.csv\", index=False)\n",
        "\n",
        "train_dataset = CT_Data(csv_file='Dataset/Train.csv', root_dir='/content')\n",
        "val_dataset = CT_Data(csv_file='Dataset/Validation.csv', root_dir='/content')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=37, shuffle=True, num_workers=4)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=20, shuffle=True, num_workers=4)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPXR8tEIyhyw"
      },
      "source": [
        "## U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpsspcUc9AIY"
      },
      "source": [
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, channel_in, channel_out):\n",
        "        super(Up, self).__init__()\n",
        "\n",
        "        ###########################################\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "        self.conv = nn.Sequential(\n",
        "            Conv2D(channel_in, channel_in, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_in),\n",
        "            nn.ReLU(inplace=True),\n",
        "            Conv2D(channel_in, channel_out, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        ###########################################\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "\n",
        "        ###########################################\n",
        "        x1 = self.upsample(x1)\n",
        "        diff_X = x1.size()[2] - x2.size()[2]\n",
        "        diff_Y = x1.size()[3] - x2.size()[3]\n",
        "        x2 = F.pad(x2, (diff_X // 2, int(diff_X / 2),diff_Y // 2, int(diff_Y / 2)))\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x  \n",
        "        ###########################################\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, channel_in, channel_out):\n",
        "        super(Down, self).__init__()\n",
        "\n",
        "        ###########################################\n",
        "        self.conv = nn.Sequential(\n",
        "            Conv2D(channel_in, channel_in, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_in),\n",
        "            nn.ReLU(inplace=True),\n",
        "            Conv2D(channel_in, channel_out, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        ###########################################\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        ###########################################\n",
        "        x = F.max_pool2d(x,2)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "        ###########################################\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, channel_in, classes):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        ###########################################\n",
        "        self.input_conv = nn.Sequential(\n",
        "            Conv2D(channel_in, channel_in, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(channel_in),\n",
        "            nn.ReLU(inplace=True),\n",
        "            Conv2D(channel_in, 64, kernel_size = 3, padding = 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512,512)\n",
        "        self.up1 = Up(1024,256)\n",
        "        self.up2 = Up(512, 128)\n",
        "        self.up3 = Up(256, 64)\n",
        "        self.up4 = Up(128, 32)\n",
        "        self.output_conv = nn.Conv2d(32, classes, kernel_size = 1)  \n",
        "        ###########################################\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        ###########################################\n",
        "        x1 = self.input_conv(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5,x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        output = self.output_conv(x)\n",
        "        return F.sigmoid(output)\n",
        "        ###########################################\n",
        "    \n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        init.xavier_uniform(m.weight, gain=numpy.sqrt(2.0))\n",
        "        init.constant(m.bias, 0.1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IHuR2DYy7P9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsaOLU5rb7WH"
      },
      "source": [
        "def iou_score(output, target):\n",
        "    smooth = 1e-8\n",
        "    oss = output > 0.5\n",
        "    tss = target > 0.5\n",
        "    intersection = (oss & tss).sum(axis=[1,2,3])\n",
        "    union = (oss | tss).sum(axis=[1,2,3])\n",
        "    return ((intersection + smooth) / (union + smooth)).mean()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgYtlFne9U3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9426c39a-5bcd-46d6-bf16-488ac14c0b33"
      },
      "source": [
        "freq = 1\n",
        "model = UNet(1, 1)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "def train(model, epoch):\n",
        "    ###########################################\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    ########### Set model to train mode\n",
        "    ###########################################\n",
        "    for batch_idx, data in enumerate(train_dataloader):\n",
        "        ###########################################\n",
        "        data, target = Variable(data[\"image\"]), Variable(data[\"mask\"])\n",
        "        # print(f\"unique:{torch.unique(target)}\")\n",
        "        min_v = torch.min(target)\n",
        "        range_v = torch.max(target) - min_v\n",
        "        target = (target - min_v) / range_v\n",
        "        # print(f\"unique:{torch.unique(normalised)}\")\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(data.float())\n",
        "        # print(f\"unique:{torch.unique(output)}\")\n",
        "        loss = criterion(output.float(), target.float())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ###########################################\n",
        "\n",
        "        ###########################################\n",
        "        if batch_idx % freq == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_dataloader.dataset)}'\n",
        "            f' ({100. * batch_idx / len(train_dataloader):.0f}%)]\\tLoss: { loss.data:.6f}')\n",
        "        ########### Print loss and accuracy for train\n",
        "        ###########################################\n",
        "\n",
        "def test(model):\n",
        "    ###########################################\n",
        "    model.eval()\n",
        "    ########### Set model to validation mode\n",
        "    ###########################################\n",
        "    test_loss = 0\n",
        "    total_iou = 0.0\n",
        "    for data in val_dataloader:\n",
        "        ###########################################\n",
        "        data, target = Variable(data[\"image\"], volatile=True), Variable(data[\"mask\"])\n",
        "        output = model(data.float())\n",
        "        # print(output.data[0])\n",
        "        min_v = torch.min(target)\n",
        "        range_v = torch.max(target) - min_v\n",
        "        target = (target - min_v) / range_v\n",
        "        test_loss += criterion(output.float(), target.float()).data # sum up batch loss\n",
        "        total_iou += iou_score(output, target)\n",
        "    test_loss /= len(val_dataloader.dataset)\n",
        "    total_iou /= len(val_dataloader)\n",
        "    print(f\"Average Loss: {test_loss} and IoU : {total_iou}\")\n",
        "        ########### calculate and Print loss and accuracy for test(or validation)\n",
        "        ###########################################\n",
        "\n",
        "\n",
        "Num_of_eopchs = 20\n",
        "\n",
        "for epoch in range(1, Num_of_eopchs+1):\n",
        "    train(model, epoch)\n",
        "    test(model)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/185 (0%)]\tLoss: 0.795207\n",
            "Train Epoch: 1 [37/185 (20%)]\tLoss: 0.697212\n",
            "Train Epoch: 1 [74/185 (40%)]\tLoss: 0.639077\n",
            "Train Epoch: 1 [111/185 (60%)]\tLoss: 0.606457\n",
            "Train Epoch: 1 [148/185 (80%)]\tLoss: 0.559028\n",
            "Average Loss: 0.03519650548696518 and IoU : 0.24913054704666138\n",
            "Train Epoch: 2 [0/185 (0%)]\tLoss: 0.523921\n",
            "Train Epoch: 2 [37/185 (20%)]\tLoss: 0.491464\n",
            "Train Epoch: 2 [74/185 (40%)]\tLoss: 0.491018\n",
            "Train Epoch: 2 [111/185 (60%)]\tLoss: 0.464413\n",
            "Train Epoch: 2 [148/185 (80%)]\tLoss: 0.457676\n",
            "Average Loss: 0.033617351204156876 and IoU : 0.21056808531284332\n",
            "Train Epoch: 3 [0/185 (0%)]\tLoss: 0.444232\n",
            "Train Epoch: 3 [37/185 (20%)]\tLoss: 0.435304\n",
            "Train Epoch: 3 [74/185 (40%)]\tLoss: 0.431345\n",
            "Train Epoch: 3 [111/185 (60%)]\tLoss: 0.407353\n",
            "Train Epoch: 3 [148/185 (80%)]\tLoss: 0.418745\n",
            "Average Loss: 0.031244149431586266 and IoU : 0.018231166526675224\n",
            "Train Epoch: 4 [0/185 (0%)]\tLoss: 0.402628\n",
            "Train Epoch: 4 [37/185 (20%)]\tLoss: 0.400667\n",
            "Train Epoch: 4 [74/185 (40%)]\tLoss: 0.403930\n",
            "Train Epoch: 4 [111/185 (60%)]\tLoss: 0.403331\n",
            "Train Epoch: 4 [148/185 (80%)]\tLoss: 0.390237\n",
            "Average Loss: 0.02891477569937706 and IoU : 0.07164839655160904\n",
            "Train Epoch: 5 [0/185 (0%)]\tLoss: 0.407848\n",
            "Train Epoch: 5 [37/185 (20%)]\tLoss: 0.380391\n",
            "Train Epoch: 5 [74/185 (40%)]\tLoss: 0.375566\n",
            "Train Epoch: 5 [111/185 (60%)]\tLoss: 0.387316\n",
            "Train Epoch: 5 [148/185 (80%)]\tLoss: 0.381844\n",
            "Average Loss: 0.02473258040845394 and IoU : 0.6123734712600708\n",
            "Train Epoch: 6 [0/185 (0%)]\tLoss: 0.380746\n",
            "Train Epoch: 6 [37/185 (20%)]\tLoss: 0.379388\n",
            "Train Epoch: 6 [74/185 (40%)]\tLoss: 0.364095\n",
            "Train Epoch: 6 [111/185 (60%)]\tLoss: 0.391576\n",
            "Train Epoch: 6 [148/185 (80%)]\tLoss: 0.372052\n",
            "Average Loss: 0.021171651780605316 and IoU : 0.8111132383346558\n",
            "Train Epoch: 7 [0/185 (0%)]\tLoss: 0.379310\n",
            "Train Epoch: 7 [37/185 (20%)]\tLoss: 0.375183\n",
            "Train Epoch: 7 [74/185 (40%)]\tLoss: 0.371192\n",
            "Train Epoch: 7 [111/185 (60%)]\tLoss: 0.357152\n",
            "Train Epoch: 7 [148/185 (80%)]\tLoss: 0.369057\n",
            "Average Loss: 0.019901514053344727 and IoU : 0.8136740922927856\n",
            "Train Epoch: 8 [0/185 (0%)]\tLoss: 0.380323\n",
            "Train Epoch: 8 [37/185 (20%)]\tLoss: 0.359855\n",
            "Train Epoch: 8 [74/185 (40%)]\tLoss: 0.355388\n",
            "Train Epoch: 8 [111/185 (60%)]\tLoss: 0.367220\n",
            "Train Epoch: 8 [148/185 (80%)]\tLoss: 0.359685\n",
            "Average Loss: 0.019068118184804916 and IoU : 0.8269330859184265\n",
            "Train Epoch: 9 [0/185 (0%)]\tLoss: 0.359843\n",
            "Train Epoch: 9 [37/185 (20%)]\tLoss: 0.353945\n",
            "Train Epoch: 9 [74/185 (40%)]\tLoss: 0.362103\n",
            "Train Epoch: 9 [111/185 (60%)]\tLoss: 0.354834\n",
            "Train Epoch: 9 [148/185 (80%)]\tLoss: 0.364337\n",
            "Average Loss: 0.01874711737036705 and IoU : 0.8131701350212097\n",
            "Train Epoch: 10 [0/185 (0%)]\tLoss: 0.353830\n",
            "Train Epoch: 10 [37/185 (20%)]\tLoss: 0.363657\n",
            "Train Epoch: 10 [74/185 (40%)]\tLoss: 0.349529\n",
            "Train Epoch: 10 [111/185 (60%)]\tLoss: 0.352053\n",
            "Train Epoch: 10 [148/185 (80%)]\tLoss: 0.356192\n",
            "Average Loss: 0.018433675169944763 and IoU : 0.8306480646133423\n",
            "Train Epoch: 11 [0/185 (0%)]\tLoss: 0.354808\n",
            "Train Epoch: 11 [37/185 (20%)]\tLoss: 0.350282\n",
            "Train Epoch: 11 [74/185 (40%)]\tLoss: 0.357050\n",
            "Train Epoch: 11 [111/185 (60%)]\tLoss: 0.343021\n",
            "Train Epoch: 11 [148/185 (80%)]\tLoss: 0.349293\n",
            "Average Loss: 0.018149344250559807 and IoU : 0.8466652631759644\n",
            "Train Epoch: 12 [0/185 (0%)]\tLoss: 0.348611\n",
            "Train Epoch: 12 [37/185 (20%)]\tLoss: 0.354097\n",
            "Train Epoch: 12 [74/185 (40%)]\tLoss: 0.344852\n",
            "Train Epoch: 12 [111/185 (60%)]\tLoss: 0.341323\n",
            "Train Epoch: 12 [148/185 (80%)]\tLoss: 0.347508\n",
            "Average Loss: 0.01794494315981865 and IoU : 0.8490195274353027\n",
            "Train Epoch: 13 [0/185 (0%)]\tLoss: 0.352482\n",
            "Train Epoch: 13 [37/185 (20%)]\tLoss: 0.338675\n",
            "Train Epoch: 13 [74/185 (40%)]\tLoss: 0.344096\n",
            "Train Epoch: 13 [111/185 (60%)]\tLoss: 0.338954\n",
            "Train Epoch: 13 [148/185 (80%)]\tLoss: 0.344054\n",
            "Average Loss: 0.01794489286839962 and IoU : 0.847145676612854\n",
            "Train Epoch: 14 [0/185 (0%)]\tLoss: 0.338256\n",
            "Train Epoch: 14 [37/185 (20%)]\tLoss: 0.340891\n",
            "Train Epoch: 14 [74/185 (40%)]\tLoss: 0.337903\n",
            "Train Epoch: 14 [111/185 (60%)]\tLoss: 0.341401\n",
            "Train Epoch: 14 [148/185 (80%)]\tLoss: 0.345224\n",
            "Average Loss: 0.017692750319838524 and IoU : 0.8524484634399414\n",
            "Train Epoch: 15 [0/185 (0%)]\tLoss: 0.335907\n",
            "Train Epoch: 15 [37/185 (20%)]\tLoss: 0.337742\n",
            "Train Epoch: 15 [74/185 (40%)]\tLoss: 0.334337\n",
            "Train Epoch: 15 [111/185 (60%)]\tLoss: 0.340423\n",
            "Train Epoch: 15 [148/185 (80%)]\tLoss: 0.338695\n",
            "Average Loss: 0.017701607197523117 and IoU : 0.8538316488265991\n",
            "Train Epoch: 16 [0/185 (0%)]\tLoss: 0.331990\n",
            "Train Epoch: 16 [37/185 (20%)]\tLoss: 0.327833\n",
            "Train Epoch: 16 [74/185 (40%)]\tLoss: 0.337015\n",
            "Train Epoch: 16 [111/185 (60%)]\tLoss: 0.338413\n",
            "Train Epoch: 16 [148/185 (80%)]\tLoss: 0.339127\n",
            "Average Loss: 0.017666546627879143 and IoU : 0.8498759865760803\n",
            "Train Epoch: 17 [0/185 (0%)]\tLoss: 0.336477\n",
            "Train Epoch: 17 [37/185 (20%)]\tLoss: 0.333091\n",
            "Train Epoch: 17 [74/185 (40%)]\tLoss: 0.334272\n",
            "Train Epoch: 17 [111/185 (60%)]\tLoss: 0.327104\n",
            "Train Epoch: 17 [148/185 (80%)]\tLoss: 0.330893\n",
            "Average Loss: 0.017369605600833893 and IoU : 0.8580742478370667\n",
            "Train Epoch: 18 [0/185 (0%)]\tLoss: 0.331760\n",
            "Train Epoch: 18 [37/185 (20%)]\tLoss: 0.333141\n",
            "Train Epoch: 18 [74/185 (40%)]\tLoss: 0.326274\n",
            "Train Epoch: 18 [111/185 (60%)]\tLoss: 0.321714\n",
            "Train Epoch: 18 [148/185 (80%)]\tLoss: 0.339672\n",
            "Average Loss: 0.017282750457525253 and IoU : 0.8534456491470337\n",
            "Train Epoch: 19 [0/185 (0%)]\tLoss: 0.326507\n",
            "Train Epoch: 19 [37/185 (20%)]\tLoss: 0.332461\n",
            "Train Epoch: 19 [74/185 (40%)]\tLoss: 0.323157\n",
            "Train Epoch: 19 [111/185 (60%)]\tLoss: 0.333124\n",
            "Train Epoch: 19 [148/185 (80%)]\tLoss: 0.322470\n",
            "Average Loss: 0.017232421785593033 and IoU : 0.8580657243728638\n",
            "Train Epoch: 20 [0/185 (0%)]\tLoss: 0.330187\n",
            "Train Epoch: 20 [37/185 (20%)]\tLoss: 0.317966\n",
            "Train Epoch: 20 [74/185 (40%)]\tLoss: 0.326452\n",
            "Train Epoch: 20 [111/185 (60%)]\tLoss: 0.333047\n",
            "Train Epoch: 20 [148/185 (80%)]\tLoss: 0.318109\n",
            "Average Loss: 0.01708180643618107 and IoU : 0.8601279854774475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlWhUQcMyW8x"
      },
      "source": [
        "## Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPMTvh_3zByn"
      },
      "source": [
        "visualize output of your trained network on 5 data from validation dataset, and compare it with ground truth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUZ-5KH1jzpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "1e93b200-d85b-4509-bf74-11c7557be041"
      },
      "source": [
        "\n",
        "# get some random training images\n",
        "dataiter = iter(val_dataloader)\n",
        "batch = dataiter.next()\n",
        "images, labels = batch['image'], batch['mask']\n",
        "with torch.no_grad():\n",
        "  outputs = model(images.float())\n",
        "\n",
        "def show(img, ax):\n",
        "    npimg = img.numpy()\n",
        "    ax.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "out_samples = outputs[:5]\n",
        "label_samples = labels[:5]\n",
        "pred_grid = utils.make_grid(255*(out_samples >= 0.5) , nrow=5)\n",
        "gt_grid = utils.make_grid(label_samples , nrow=5)\n",
        "f, (ax0,ax1) = plt.subplots(1,2,figsize=(15,15))\n",
        "ax0.set_title('ground truth')\n",
        "ax1.set_title('predictions')\n",
        "show(gt_grid, ax0)\n",
        "show(pred_grid, ax1)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLThQ1kxzT0o"
      },
      "source": [
        "## Improve U-Net (bonus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3RHpUhyzm1Z"
      },
      "source": [
        "improve U-Net and compare accuracy and networks outputs with previous parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9tj1WoVzUms"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}